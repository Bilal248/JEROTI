{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ce727cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipynb.fs.full.ModelTraining  import *\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score, precision_score, recall_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4a63ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agreement between Isolation Forest and DBSCAN: 99.2084%\n",
      "\n",
      "Relative Confusion Matrix between models:\n",
      "DBSCAN               0    1\n",
      "IsolationForest            \n",
      "0                42299   98\n",
      "1                  241  188\n"
     ]
    }
   ],
   "source": [
    "df['dbscan_label'] = df['dbscan_anomaly']\n",
    "\n",
    "\n",
    "df['iso_label'] = df['anomaly'].map({-1: 1, 1: 0})\n",
    "\n",
    "\n",
    "agreement = (df['iso_label'] == df['dbscan_label']).mean()\n",
    "\n",
    "print(f\"Agreement between Isolation Forest and DBSCAN: {agreement:.4%}\")\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "conf_matrix = pd.crosstab(\n",
    "    df['iso_label'], \n",
    "    df['dbscan_label'], \n",
    "    rownames=['IsolationForest'], \n",
    "    colnames=['DBSCAN']\n",
    ")\n",
    "print(\"\\nRelative Confusion Matrix between models:\")\n",
    "print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992427b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "F1 Score: 0.5259\n",
      "Precision: 0.6573\n",
      "Recall: 0.4382\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00     42397\n",
      "           1       0.66      0.44      0.53       429\n",
      "\n",
      "    accuracy                           0.99     42826\n",
      "   macro avg       0.83      0.72      0.76     42826\n",
      "weighted avg       0.99      0.99      0.99     42826\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y_true = df['iso_label']      \n",
    "y_pred = df['dbscan_label']    \n",
    "\n",
    "f1 = f1_score(y_true, y_pred)\n",
    "precision = precision_score(y_true, y_pred)\n",
    "recall = recall_score(y_true, y_pred)\n",
    "\n",
    "print(f\"\\nF1 Score: {f1:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_true, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1053d5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ada_label'] = ada.predict(X_scaled)\n",
    "df['ada_prob'] = ada.predict_proba(X_scaled)[:, 1]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8ac7b60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ada_label'].unique()\n",
    "df['ada_label'] = df['ada_label'].map({-1: 1, 1: 0})    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a28dedc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.3524\n",
      "Precision: 0.3528\n",
      "Recall: 0.3520\n",
      "\n",
      "Confusion Matrix:\n",
      "[[42120   277]\n",
      " [  278   151]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99     42397\n",
      "           1       0.35      0.35      0.35       429\n",
      "\n",
      "    accuracy                           0.99     42826\n",
      "   macro avg       0.67      0.67      0.67     42826\n",
      "weighted avg       0.99      0.99      0.99     42826\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_true = df['iso_label']\n",
    "y_pred = df['ada_label']\n",
    "\n",
    "f1 = f1_score(y_true, y_pred)\n",
    "precision = precision_score(y_true, y_pred)\n",
    "recall = recall_score(y_true, y_pred)\n",
    "\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_true, y_pred))\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3e7e12e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.4846\n",
      "Precision: 0.4042\n",
      "Recall: 0.6049\n",
      "\n",
      "Confusion Matrix:\n",
      "[[42285   255]\n",
      " [  113   173]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00     42540\n",
      "           1       0.40      0.60      0.48       286\n",
      "\n",
      "    accuracy                           0.99     42826\n",
      "   macro avg       0.70      0.80      0.74     42826\n",
      "weighted avg       0.99      0.99      0.99     42826\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_true = df['dbscan_label']\n",
    "y_pred = df['ada_label']\n",
    "\n",
    "f1 = f1_score(y_true, y_pred)\n",
    "precision = precision_score(y_true, y_pred)\n",
    "recall = recall_score(y_true, y_pred)\n",
    "\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_true, y_pred))\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_true, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "JEROTI (3.12.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
